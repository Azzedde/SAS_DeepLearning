{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SAS Event Stream Processing Project (including: project, publisher & subscriber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SASESP():\n",
    "    \"\"\"\n",
    "    Class creates ESP project inlcuding Tiny YOLO model\n",
    "    @author Michael Gorkow\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.esp, self.esp_project, self.pub, self.sub = self.esp_buildproject()\n",
    "        threading.Thread(target=self.sub.ws.run_forever, daemon=True).start()\n",
    "    def esp_buildproject(self):\n",
    "        esp = esppy.ESP(hostname='http://localhost:9900')\n",
    "        esp_project = esp.create_project('test', n_threads=10)\n",
    "        esp_project.pubsub = 'manual'\n",
    "        esp_project.add_continuous_query('contquery')\n",
    "\n",
    "        # Window: Video Capture\n",
    "        vid_capture = esp.SourceWindow(schema=('id*:int64', 'image:blob'),\n",
    "                                       index_type='empty', insert_only=True, pubsub=True)\n",
    "        #vid_capture.pubsub = True\n",
    "        esp_project.windows['w_input'] = vid_capture\n",
    "\n",
    "        # Window: Video Resize\n",
    "        vid_capture_resize = esp.CalculateWindow(schema=('id*:int64,image:blob,_image_:blob'),\n",
    "                                                 index_type='empty',\n",
    "                                                 algorithm='ImageProcessing', \n",
    "                                                 name='resized', \n",
    "                                                 function='resize',\n",
    "                                                 height=416, \n",
    "                                                 width=416, \n",
    "                                                 input_map=dict(imageInput='image'), \n",
    "                                                 output_map=dict(imageOutput='_image_'))\n",
    "        esp_project.windows['w_resize'] = vid_capture_resize\n",
    "\n",
    "        # Window: Model Reader\n",
    "        model_reader = esp.ModelReaderWindow()\n",
    "        esp_project.windows['w_reader'] = model_reader\n",
    "\n",
    "        # Window: Model Request\n",
    "        model_request = esp.SourceWindow(schema=('req_id*:int64', 'req_key:string', 'req_val:string'),\n",
    "                                         index_type='empty', \n",
    "                                         insert_only=True)\n",
    "        esp_project.windows['w_request'] = model_request\n",
    "\n",
    "        # Window: Model Score\n",
    "        model_score = esp.ScoreWindow(pubsub=True)\n",
    "        model_score.pubsub = True\n",
    "        model_score.add_offline_model(model_type='astore')\n",
    "        def score_window_fields(number_objects):\n",
    "            _field = \"id*:int64,image:blob,_image_:blob,_nObjects_:double,\"\n",
    "            for obj in range(0,number_objects):\n",
    "                _field += \"_Object\" + str(obj) + \"_:string,\"\n",
    "                _field += \"_P_Object\" + str(obj) + \"_:double,\"\n",
    "                _field += \"_Object\" + str(obj) + \"_x:double,\"\n",
    "                _field += \"_Object\" + str(obj) + \"_y:double,\"\n",
    "                _field += \"_Object\" + str(obj) + \"_width:double,\"\n",
    "                _field += \"_Object\" + str(obj) + \"_height:double,\"\n",
    "            return _field[:-1]\n",
    "        model_score.schema_string = score_window_fields(20)\n",
    "        esp_project.windows['w_score'] = model_score\n",
    "\n",
    "        # Connections\n",
    "        vid_capture.add_target(vid_capture_resize, role='data')\n",
    "        vid_capture_resize.add_target(model_score, role='data')\n",
    "        model_request.add_target(model_reader, role='request')\n",
    "        model_reader.add_target(model_score, role='model')\n",
    "\n",
    "        # Load Project\n",
    "        esp.load_project(esp_project)\n",
    "\n",
    "        # Publisher: Send Model\n",
    "        #pub = model_request.create_publisher(blocksize=1, rate=0, pause=0, dateformat='%Y%dT%H:%M:%S.%f', opcode='insert', format='csv')\n",
    "        pub = model_request.create_publisher(opcode='insert', format='csv')\n",
    "        pub.send('i,n,1,\"usegpuesp\",\"1\"\\n')\n",
    "        pub.send('i,n,2,\"ndevices\",\"1\"\\n')\n",
    "        pub.send('i,n,3,\"action\",\"load\"\\n')\n",
    "        pub.send('i,n,4,\"type\",\"astore\"\\n')\n",
    "        pub.send('i,n,5,\"reference\",\"/data/notebooks/deep_learning_examples/models/object_detection/tiny_yolov2_313cls/Tiny-Yolov2.astore\"\\n')\n",
    "        pub.send('i,n,6,,\\n')\n",
    "        pub.close()\n",
    "\n",
    "        # Publisher: Send Video; Subscriber: Retrieve Results\n",
    "        pub = vid_capture.create_publisher(blocksize=1, rate=0, pause=0, opcode='insert', format='csv')\n",
    "        sub = self.esp_sub()\n",
    "        return esp, esp_project, pub, sub\n",
    "        \n",
    "    class esp_sub():\n",
    "        def __init__(self):\n",
    "            self.ws = websocket.WebSocketApp(\"ws://localhost:9900/SASESP/subscribers/test/contquery/w_score/?format=json&mode=streaming&pagesize=1\",\n",
    "                                             on_message = self.on_message,\n",
    "                                             on_error = self.on_error,\n",
    "                                             on_close = self.on_close)\n",
    "            self.ws.on_open = self.on_open\n",
    "            self.results = np.zeros((720,960,3), np.uint8)\n",
    "            self.cmd = []\n",
    "            self.facetrack = False\n",
    "            self.detect_objects = 'list'\n",
    "            self.object_list = ['Human face', 'Shirt', 'Person', 'Dress', 'Fashion accessory', 'Glasses', 'Handbag', 'Hat', 'Jewelry', 'Rifle', 'Trousers', 'Skirt', 'Weapon']\n",
    "            self.color_palette = [\n",
    "                (0,64,255), #red\n",
    "                (0,191,255), #orange\n",
    "                (0,255,255), #yellow\n",
    "                (0,255,64), #green\n",
    "                (255,255,0), #blue\n",
    "                (250,0,250), #pink\n",
    "                (250,0,125), #purple\n",
    "                (167,250,0), #turquoise\n",
    "                (255,200,0), #light-blue\n",
    "                (255,100,0), #dark-blue\n",
    "                (0,255,100), #light-green\n",
    "                (155,0,255), #pink\n",
    "                (255,170,0) #blue\n",
    "            ]\n",
    "            #BGR Colorcodes\n",
    "            self.obj_colors = {}\n",
    "            i = 0\n",
    "            for _object in self.object_list:\n",
    "                self.obj_colors[_object] = self.color_palette[i]\n",
    "                i += 1\n",
    "                \n",
    "        def on_message(self, message):\n",
    "            cmd = []\n",
    "            try:\n",
    "                data = json.loads(message)\n",
    "                row = data['events'][0]['event']\n",
    "                numberOfObjects = data['events'][0]['event']['_nObjects_']\n",
    "                imageBufferBase64 = data['events'][0]['event']['image']['image']\n",
    "                nparr = np.frombuffer(base64.b64decode(imageBufferBase64), dtype=np.uint8)\n",
    "                frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "                image_h, image_w,_ = frame.shape\n",
    "                for i in range(0, int(float(numberOfObjects))):\n",
    "                    obj = row['_Object' + str(i) + '_'].strip()\n",
    "                    prob = float(row['_P_Object' + str(i) + '_'])\n",
    "                    probability = \" (\" + str(round(prob * 100, 2)) + \"%)\"\n",
    "                    x = float(row['_Object' + str(i) + '_x'])\n",
    "                    y = float(row['_Object' + str(i) + '_y'])\n",
    "                    width = float(row['_Object' + str(i) + '_width'])\n",
    "                    height = float(row['_Object' + str(i) + '_height'])\n",
    "\n",
    "                    x1 = int(image_w * (x - width / 2))\n",
    "                    y1 = int(image_h * (y - height/ 2))\n",
    "                    x2 = int(image_w * (x + width / 2))\n",
    "                    y2 = int(image_h * (y + height/ 2))\n",
    "                    if self.detect_objects == 'all':\n",
    "                        bbox_color = (64,255,0)\n",
    "                        border_offset = 3\n",
    "                        cv2.rectangle(frame,(x1,y1),(x2,y2),bbox_color,1)\n",
    "                        (label_width, label_height), baseline = cv2.getTextSize(obj + probability, cv2.FONT_HERSHEY_DUPLEX, 0.4, 1)\n",
    "                        cv2.rectangle(frame,(x1,y1),(x1+label_width+10,y1-label_height-border_offset-10),bbox_color,-1)\n",
    "                        cv2.putText(frame, obj + probability, (x1+5, y1-border_offset-5), cv2.FONT_HERSHEY_DUPLEX, 0.4, (0, 0, 0), 1,cv2.LINE_AA)\n",
    "                        cv2.putText(frame, str(image_w), (200, 350), cv2.FONT_HERSHEY_DUPLEX, 0.4, (0, 0, 0), 1,cv2.LINE_AA)\n",
    "                        cv2.putText(frame, str(image_h), (200, 400), cv2.FONT_HERSHEY_DUPLEX, 0.4, (0, 0, 0), 1,cv2.LINE_AA)\n",
    "                    if self.detect_objects == 'list':\n",
    "                        if obj in self.obj_colors:\n",
    "                            bbox_color = self.obj_colors[obj]\n",
    "                            border_offset = 3\n",
    "                            cv2.rectangle(frame,(x1,y1),(x2,y2),bbox_color,1)\n",
    "                            (label_width, label_height), baseline = cv2.getTextSize(obj + probability, cv2.FONT_HERSHEY_DUPLEX, 0.4, 1)\n",
    "                            cv2.rectangle(frame,(x1,y1),(x1+label_width+10,y1-label_height-border_offset-10),bbox_color,-1)\n",
    "                            cv2.putText(frame, obj + probability, (x1+5, y1-border_offset-5), cv2.FONT_HERSHEY_DUPLEX, 0.4, (0, 0, 0), 1,cv2.LINE_AA)\n",
    "                    if self.detect_objects == 'human':\n",
    "                        if obj == 'Human face':\n",
    "                            bbox_color = (64,255,0)\n",
    "                            border_offset = 3\n",
    "                            cv2.rectangle(frame,(x1,y1),(x2,y2),bbox_color,1)\n",
    "                            (label_width, label_height), baseline = cv2.getTextSize(obj + probability, cv2.FONT_HERSHEY_DUPLEX, 0.4, 1)\n",
    "                            cv2.rectangle(frame,(x1,y1),(x1+label_width+10,y1-label_height-border_offset-10),bbox_color,-1)\n",
    "                            cv2.putText(frame, obj + probability, (x1+5, y1-border_offset-5), cv2.FONT_HERSHEY_DUPLEX, 0.4, (0, 0, 0), 1,cv2.LINE_AA)\n",
    "                    if self.facetrack == True:\n",
    "                        cv2.putText(frame,  'Facetrack ON', (0,20), cv2.FONT_HERSHEY_DUPLEX, 0.4, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "                        if obj == 'Human face':\n",
    "                            bbox_color = (64,255,0)\n",
    "                            cmd = []\n",
    "                            cv2.rectangle(frame,(int(image_w*0.2),int(image_h*0.2)),(int(image_w*0.8),int(image_h*0.8)),bbox_color,1)\n",
    "                            try:\n",
    "                                bbox_center_x = int(x*image_w)\n",
    "                                bbox_center_y = int(y*image_h)\n",
    "                                image_center_x = int(image_w/2)\n",
    "                                image_center_y = int(image_h/2)\n",
    "                                dist_to_x = bbox_center_x - image_center_x\n",
    "                                dist_to_y = bbox_center_y - image_center_y\n",
    "                                bbox_width = x2 - x1\n",
    "                                cv2.line(frame, (bbox_center_x, bbox_center_y), (image_center_x, image_center_y), (0, 255, 0), thickness=3, lineType=8)\n",
    "                                #cv2.putText(frame,  'DIST_TO_X:' + str(dist_to_x), (0,40), cv2.FONT_HERSHEY_DUPLEX, 0.4, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "                                #cv2.putText(frame,  'DIST_TO_Y:'  + str(dist_to_y), (0,60), cv2.FONT_HERSHEY_DUPLEX, 0.4, (255,255, 255), 1, cv2.LINE_AA)\n",
    "                                if dist_to_x > 0:\n",
    "                                    if dist_to_x > 100:\n",
    "                                        cmd.append( 'd') #Right\n",
    "                                if dist_to_x < 0:\n",
    "                                    if dist_to_x < -100:\n",
    "                                        cmd.append( 'a') #left\n",
    "                                if dist_to_y > 0:\n",
    "                                    if dist_to_y > 100:\n",
    "                                        cmd.append('Key.down') #down\n",
    "                                if dist_to_y < 0:\n",
    "                                    if dist_to_y < -100:\n",
    "                                        cmd.append('Key.up') #up\n",
    "                                if bbox_width < (image_w*0.1):\n",
    "                                    cmd.append('w') #forward\n",
    "                                if bbox_width > (image_w*0.1):\n",
    "                                    cmd.append('s') #backward\n",
    "                            except Exception as e: \n",
    "                                print('Facetrack Error:', e)\n",
    "                self.results = frame\n",
    "                self.cmd = cmd\n",
    "            except Exception as e:\n",
    "                print(e)                \n",
    "\n",
    "        def on_error(self, error):\n",
    "            print(error)\n",
    "\n",
    "        def on_close(self):\n",
    "            print(\"### closed ###\")\n",
    "\n",
    "        def on_open(self):\n",
    "            print('open')\n",
    "            \n",
    "\n",
    "    def send(self, frame):\n",
    "        _, buffer = cv2.imencode('.jpg', frame)\n",
    "        encoded_string = base64.b64encode(buffer)\n",
    "        strToSend = 'i, n, ' + str(int(time.time()*100)) + ',' + encoded_string.decode() + ',' + '\\n'\n",
    "        self.pub.send(strToSend)\n",
    "    \n",
    "    # Class function to retrieve ESP results\n",
    "    def get_results(self):\n",
    "        return self.sub.results\n",
    "    \n",
    "    def get_cmd(self):\n",
    "        return self.sub.cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Drone Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TelloCV(object):\n",
    "    \n",
    "    def __init__(self, esp):\n",
    "        self.prev_flight_data = None\n",
    "        self.record = False\n",
    "        #self.tracking = False\n",
    "        self.keydown = False\n",
    "        self.date_fmt = '%Y-%m-%d_%H%M%S'\n",
    "        self.speed = 25\n",
    "        self.out_file = None\n",
    "        self.out_stream = None\n",
    "        self.out_name = None\n",
    "        self.start_time = time.time()\n",
    "        self.esp = esp\n",
    "        self.FPS = 25\n",
    "        self.video_out = None\n",
    "        self.time_last_cmd = time.time()\n",
    "        threading.Thread(target=self.run, daemon=True).start()\n",
    "        \n",
    "    def run(self):\n",
    "        self.drone = tellopy.Tello()\n",
    "        self.init_drone()\n",
    "        self.init_controls()\n",
    "        # container for processing the packets into frames\n",
    "        try:\n",
    "            self.container = av.open(self.drone.get_video_stream())\n",
    "            self.vid_stream = self.container.streams.video[0]\n",
    "        except:\n",
    "            exit(0)\n",
    "        prev = 0\n",
    "        for packet in self.container.demux((self.vid_stream,)):\n",
    "            for frame in packet.decode():\n",
    "                time_elapsed = time.time() - prev\n",
    "                if time_elapsed > 1./self.FPS:\n",
    "                    prev = time.time()\n",
    "                    try:\n",
    "                        self.handle_esp_cmd()\n",
    "                        image = self.process_frame(frame)\n",
    "                        #image = cv2.resize(image, (1280,720))\n",
    "                        cv2.imshow('SAS Drone Demo (YOLO Object Detection)', image)\n",
    "                        _ = cv2.waitKey(1) & 0xFF\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "\n",
    "    def init_drone(self):\n",
    "        \"\"\"Connect, uneable streaming and subscribe to events\"\"\"\n",
    "        # self.drone.log.set_level(2)\n",
    "        self.drone.connect()\n",
    "        self.drone.start_video()\n",
    "        self.drone.subscribe(self.drone.EVENT_FLIGHT_DATA,\n",
    "                             self.flight_data_handler)\n",
    "        self.drone.subscribe(self.drone.EVENT_FILE_RECEIVED,\n",
    "                             self.handle_flight_received)\n",
    "\n",
    "    def on_press(self, keyname):\n",
    "        \"\"\"handler for keyboard listener\"\"\"\n",
    "        if self.keydown:\n",
    "            return\n",
    "        try:\n",
    "            self.keydown = True\n",
    "            keyname = str(keyname).strip('\\'')\n",
    "            print('+' + keyname)\n",
    "            if keyname == 'Key.esc':\n",
    "                self.drone.quit()\n",
    "                cv2.destroyAllWindows()\n",
    "                self.esp.esp_project.delete()\n",
    "                exit(0)\n",
    "            if keyname in self.controls:\n",
    "                key_handler = self.controls[keyname]\n",
    "                if isinstance(key_handler, str):\n",
    "                    getattr(self.drone, key_handler)(self.speed)\n",
    "                else:\n",
    "                    key_handler(self.speed)\n",
    "        except AttributeError:\n",
    "            print('special key {0} pressed'.format(keyname))\n",
    "\n",
    "    def on_release(self, keyname):\n",
    "        \"\"\"Reset on key up from keyboard listener\"\"\"\n",
    "        self.keydown = False\n",
    "        keyname = str(keyname).strip('\\'')\n",
    "        print('-' + keyname)\n",
    "        if keyname in self.controls:\n",
    "            key_handler = self.controls[keyname]\n",
    "            if isinstance(key_handler, str):\n",
    "                getattr(self.drone, key_handler)(0)\n",
    "            else:\n",
    "                key_handler(0)\n",
    "\n",
    "    def init_controls(self):\n",
    "        \"\"\"Define keys and add listener\"\"\"\n",
    "        self.controls = {\n",
    "            'w': 'forward',\n",
    "            's': 'backward',\n",
    "            'a': 'left',\n",
    "            'd': 'right',\n",
    "            'Key.space': 'up',\n",
    "            'Key.shift': 'down',\n",
    "            'Key.shift_r': 'down',\n",
    "            'q': 'counter_clockwise',\n",
    "            'e': 'clockwise',\n",
    "            'i': lambda speed: self.drone.flip_forward(),\n",
    "            'k': lambda speed: self.drone.flip_back(),\n",
    "            'j': lambda speed: self.drone.flip_left(),\n",
    "            'l': lambda speed: self.drone.flip_right(),\n",
    "            # arrow keys for fast turns and altitude adjustments\n",
    "            'Key.left': lambda speed: self.drone.counter_clockwise(speed),\n",
    "            'Key.right': lambda speed: self.drone.clockwise(speed),\n",
    "            'Key.up': lambda speed: self.drone.up(speed),\n",
    "            'Key.down': lambda speed: self.drone.down(speed),\n",
    "            'Key.tab': lambda speed: self.drone.takeoff(),   #-> uncomment for flying...\n",
    "            'Key.backspace': lambda speed: self.drone.land(),\n",
    "            'p': lambda speed: self.palm_land(speed),\n",
    "            'r': lambda speed: self.toggle_recording(speed),\n",
    "            'z': lambda speed: self.toggle_zoom(speed),\n",
    "            'Key.enter': lambda speed: self.take_picture(speed),\n",
    "            'f': lambda speed: self.toggle_facetrack_on(speed),\n",
    "            'g': lambda speed: self.toggle_facetrack_off(speed),\n",
    "            'b': lambda speed: self.toggle_all(speed),\n",
    "            'n': lambda speed: self.toggle_list(speed),\n",
    "            'm': lambda speed: self.toggle_human(speed)\n",
    "        }\n",
    "        self.key_listener = keyboard.Listener(on_press=self.on_press,\n",
    "                                              on_release=self.on_release)\n",
    "        self.key_listener.start()\n",
    "        self.keyboard_ctrl = keyboard.Controller()\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"convert frame to cv2 image and show\"\"\"\n",
    "        self.esp.send(np.array(frame.to_image()))\n",
    "        image = self.esp.get_results()\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        image = self.write_hud(image)\n",
    "        if self.record:\n",
    "            if self.video_out != None:\n",
    "                self.video_out.write(image)\n",
    "            else:\n",
    "                print('No VideoWriter created!')\n",
    "        return image\n",
    "\n",
    "    def write_hud(self, frame):\n",
    "        \"\"\"Draw drone info, tracking and record on frame\"\"\"\n",
    "        stats = self.prev_flight_data.split('|')\n",
    "        #stats.append(\"Tracking:\" + str(self.tracking))\n",
    "        if self.drone.zoom:\n",
    "            stats.append(\"VID\")\n",
    "        else:\n",
    "            stats.append(\"PIC\")\n",
    "        if self.esp.sub.detect_objects == 'all':\n",
    "            stats.append('SHOW ALL OBJECTS')\n",
    "        if self.esp.sub.detect_objects == 'list':\n",
    "            stats.append('SHOW ITEMS FROM LIST')\n",
    "        if self.esp.sub.detect_objects == 'human':\n",
    "            stats.append('SHOWING HUMAN ONLY')\n",
    "        if self.esp.sub.facetrack:\n",
    "            stats.append('FACETRACK ON')\n",
    "        if self.record:\n",
    "            diff = int(time.time() - self.start_time)\n",
    "            mins, secs = divmod(diff, 60)\n",
    "            stats.append(\"REC {:02d}:{:02d}\".format(mins, secs))\n",
    "\n",
    "        for idx, stat in enumerate(stats):\n",
    "            text = stat.lstrip()\n",
    "            cv2.putText(frame, text, (0, 30 + (idx * 30)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1.0, (255, 255, 255), lineType=30)\n",
    "        return frame\n",
    "    \n",
    "    def toggle_recording(self, speed):\n",
    "        \"\"\"Handle recording keypress, creates output stream and file\"\"\"\n",
    "        if speed == 0:\n",
    "            return\n",
    "        self.record = not self.record\n",
    "\n",
    "        if self.record:\n",
    "            self.out_name = 'tello-' + datetime.datetime.now().strftime(self.date_fmt) + '.mp4'\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"avc1\")\n",
    "            self.video_out = cv2.VideoWriter(self.out_name,fourcc, self.FPS, (960,720))\n",
    "            print(\"Outputting video to:\", self.out_name)\n",
    "\n",
    "        if not self.record:\n",
    "            print(\"Video saved to \", self.out_name)\n",
    "            self.video_out.release()\n",
    "            self.video_out = None\n",
    "                \n",
    "    def record_vid(self, frame):\n",
    "        if self.video_out != None:\n",
    "            self.out.write(frame)\n",
    "        else:\n",
    "            print('No VideoWriter created.')\n",
    "\n",
    "    def take_picture(self, speed):\n",
    "        \"\"\"Tell drone to take picture, image sent to file handler\"\"\"\n",
    "        if speed == 0:\n",
    "            return\n",
    "        self.drone.take_picture()\n",
    "\n",
    "    def palm_land(self, speed):\n",
    "        \"\"\"Tell drone to land\"\"\"\n",
    "        if speed == 0:\n",
    "            return\n",
    "        self.drone.palm_land()\n",
    "\n",
    "    def toggle_zoom(self, speed):\n",
    "        \"\"\"\n",
    "        In \"video\" mode the self.drone sends 1280x720 frames.\n",
    "        In \"photo\" mode it sends 2592x1936 (952x720) frames.\n",
    "        The video will always be centered in the window.\n",
    "        In photo mode, if we keep the window at 1280x720 that gives us ~160px on\n",
    "        each side for status information, which is ample.\n",
    "        Video mode is harder because then we need to abandon the 16:9 display size\n",
    "        if we want to put the HUD next to the video.\n",
    "        \"\"\"\n",
    "        if speed == 0:\n",
    "            return\n",
    "        self.drone.set_video_mode(not self.drone.zoom)\n",
    "            \n",
    "    def toggle_facetrack_on(self, speed):\n",
    "        \"\"\"Handle recording keypress, creates output stream and file\"\"\"\n",
    "        if speed == 0:\n",
    "            return\n",
    "        self.esp.sub.facetrack = True\n",
    "    def toggle_facetrack_off(self, speed):\n",
    "        if speed == 0:\n",
    "            return\n",
    "        self.esp.sub.facetrack = False\n",
    "        \n",
    "    def toggle_all(self, speed):\n",
    "        self.esp.sub.detect_objects = 'all'\n",
    "    def toggle_list(self, speed):\n",
    "        self.esp.sub.detect_objects = 'list'\n",
    "    def toggle_human(self, speed):\n",
    "        self.esp.sub.detect_objects = 'human'\n",
    "\n",
    "    def flight_data_handler(self, event, sender, data):\n",
    "        \"\"\"Listener to flight data from the drone.\"\"\"\n",
    "        text = str(data)\n",
    "        if self.prev_flight_data != text:\n",
    "            self.prev_flight_data = text\n",
    "\n",
    "    def handle_flight_received(self, event, sender, data):\n",
    "        \"\"\"Create a file in ~/Pictures/ to receive image from the drone\"\"\"\n",
    "        path = '%s/Pictures/tello-%s.jpeg' % (\n",
    "            os.getenv('HOME'),\n",
    "            datetime.datetime.now().strftime(self.date_fmt))\n",
    "        with open(path, 'wb') as out_file:\n",
    "            out_file.write(data)\n",
    "        print('Saved photo to %s' % path)\n",
    "        \n",
    "    def handle_esp_cmd(self):\n",
    "        if time.time() - self.time_last_cmd > 0.1:\n",
    "            cmdlist = self.esp.get_cmd()\n",
    "            keys = {\n",
    "                'Key.up': Key.up,\n",
    "                'Key.down': Key.down\n",
    "            }\n",
    "            try:\n",
    "                released_cmd = list(set(self.prev_cmdlist) - set(cmdlist))\n",
    "            except Exception as e:\n",
    "                released_cmd = []\n",
    "            for cmd in cmdlist:\n",
    "                if cmd in keys:\n",
    "                    cmd = keys[cmd]\n",
    "                self.keyboard_ctrl.press(cmd)\n",
    "            for cmd in released_cmd:\n",
    "                if cmd in keys:\n",
    "                    cmd = keys[cmd]\n",
    "                self.keyboard_ctrl.release(cmd)\n",
    "            self.prev_cmdlist = cmdlist\n",
    "            self.time_last_cmd = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run SAS ESP Project & Drone Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test functionality with Drone\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import tellopy\n",
    "import av\n",
    "import threading\n",
    "import base64\n",
    "from pynput import keyboard\n",
    "import esppy\n",
    "import websocket\n",
    "import json\n",
    "from pynput.keyboard import Key\n",
    "\n",
    "mode = 'drone' # 'drone'\n",
    "mas_jupyter = 'jupyter'\n",
    "if mode == 'drone':\n",
    "    # Connect Tello WIFI\n",
    "    connect_counter = 0\n",
    "    success = 1\n",
    "    while success != 0:\n",
    "        os.system('nmcli device wifi rescan')\n",
    "        success = os.system('nmcli device wifi connect TELLO-FD9FBA')\n",
    "        connect_counter += 1\n",
    "        time.sleep(2)\n",
    "    print('Drone connected.')\n",
    "    \n",
    "    \n",
    "    e = SASESP() # Start ESP project\n",
    "    d = TelloCV(e) # Start drone & publish frames to ESP\n",
    "    #time.sleep(600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_sas]",
   "language": "python",
   "name": "conda-env-python_sas-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
