{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import SAS & Open Source Packages\n",
    "* SAS ESPPy for communication with SAS Event Stream Processing\n",
    "* OpenCV (cv2) to display results\n",
    "* Others for various other tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import threading\n",
    "import time\n",
    "import websocket\n",
    "import json\n",
    "import numpy as np\n",
    "import base64\n",
    "import cv2\n",
    "import esppy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build SAS Event Stream Processing Pipeline\n",
    "This code defines a simple SAS Event Stream Processing (ESP) project that will receive images and applies a Tiny YOLOv2 model on it to detect masked and unmasked faces.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to ESP and create ESP project\n",
    "esp = esppy.ESP(hostname='http://localhost:9900')\n",
    "esp_project = esp.create_project('object_detection', n_threads=10)\n",
    "esp_project.pubsub = 'manual'\n",
    "esp_project.add_continuous_query('contquery')\n",
    "\n",
    "# Window: Video Capture\n",
    "vid_capture = esp.SourceWindow(schema=('id*:int64', 'image:blob'),\n",
    "index_type='empty', insert_only=True)\n",
    "vid_capture.pubsub = True\n",
    "esp_project.windows['w_input_image'] = vid_capture\n",
    "\n",
    "# Window: Video Resize\n",
    "vid_capture_resize = esp.CalculateWindow(algorithm='ImageProcessing', \n",
    "                                         name='resized', \n",
    "                                         function='resize',\n",
    "                                         height=416, \n",
    "                                         width=416, \n",
    "                                         input_map=dict(imageInput='image'), \n",
    "                                         output_map=dict(imageOutput='_image_'))\n",
    "vid_capture_resize.schema_string = 'id*:int64,image:blob,_image_:blob'\n",
    "esp_project.windows['w_resize_image'] = vid_capture_resize\n",
    "\n",
    "# Window: Model Reader\n",
    "model_reader = esp.ModelReaderWindow()\n",
    "esp_project.windows['w_read_model'] = model_reader\n",
    "\n",
    "# Window: Model Request\n",
    "model_request = esp.SourceWindow(schema=('req_id*:int64', 'req_key:string', 'req_val:string'),index_type='empty', insert_only=True)\n",
    "esp_project.windows['w_request_model'] = model_request\n",
    "\n",
    "# Window: Model Score\n",
    "model_score = esp.ScoreWindow()\n",
    "model_score.pubsub = True\n",
    "model_score.add_offline_model(model_type='astore')\n",
    "def score_window_fields(number_objects):\n",
    "    _field = \"id*:int64,image:blob,_image_:blob,_nObjects_:double,\"\n",
    "    for obj in range(0,number_objects):\n",
    "        _field += \"_Object\" + str(obj) + \"_:string,\"\n",
    "        _field += \"_P_Object\" + str(obj) + \"_:double,\"\n",
    "        _field += \"_Object\" + str(obj) + \"_x:double,\"\n",
    "        _field += \"_Object\" + str(obj) + \"_y:double,\"\n",
    "        _field += \"_Object\" + str(obj) + \"_width:double,\"\n",
    "        _field += \"_Object\" + str(obj) + \"_height:double,\"\n",
    "    return _field[:-1]\n",
    "model_score.schema_string = score_window_fields(20)\n",
    "esp_project.windows['w_score_image'] = model_score\n",
    "\n",
    "# Connections\n",
    "vid_capture.add_target(vid_capture_resize, role='data')\n",
    "vid_capture_resize.add_target(model_score, role='data')\n",
    "model_request.add_target(model_reader, role='request')\n",
    "model_reader.add_target(model_score, role='model')\n",
    "\n",
    "# Load Project\n",
    "esp.load_project(esp_project)\n",
    "\n",
    "# Publisher: Send Model to Scoring Window\n",
    "pub = model_request.create_publisher(blocksize=1, rate=0, pause=0, dateformat='%Y%dT%H:%M:%S.%f', opcode='insert', format='csv')\n",
    "pub.send('i,n,1,\"usegpuesp\",\"1\"\\n')\n",
    "pub.send('i,n,2,\"ndevices\",\"1\"\\n')\n",
    "pub.send('i,n,3,\"action\",\"load\"\\n')\n",
    "pub.send('i,n,4,\"type\",\"astore\"\\n')\n",
    "pub.send('i,n,5,\"reference\",\"/data/notebooks/Face_Mask_Detection/Tiny-Yolov2.astore\"\\n')\n",
    "pub.send('i,n,6,,\\n')\n",
    "pub.close()\n",
    "\n",
    "# Publisher: Send Video\n",
    "pub = vid_capture.create_publisher(blocksize=1, rate=0, pause=0, opcode='insert', format='csv')\n",
    "\n",
    "# Display project\n",
    "esppy.options.display.image_scale = 0.8\n",
    "esp_project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish Image frames into the SAS Event Stream Processing Project & Receive scored data\n",
    "The class 'video_pub' extracts frames from a video (or camera) and publishes them into SAS Event Stream Processing.<br>\n",
    "The second class 'video_sub' subscribes to the Scoring-Window to receive the coordinates of detected objects.<br>\n",
    "It will display the results in a window and - optionally - save the results to a video.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to publish videos to SAS Event Stream Processing\n",
    "class video_pub():\n",
    "    def __init__(self, publisher, video_file, video_quality=95):\n",
    "        self.cap = cv2.VideoCapture(video_file)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "        self.video_quality = video_quality\n",
    "        self.pub = publisher\n",
    "        threading.Thread(target=self.stream, daemon=True).start()\n",
    "        print('Publisher started!')\n",
    "        \n",
    "    def stream(self):\n",
    "        while True:\n",
    "            ret, frame = self.cap.read()\n",
    "            encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), self.video_quality]\n",
    "            _, buffer = cv2.imencode('.jpg', frame, encode_param)\n",
    "            encoded_string = base64.b64encode(buffer)\n",
    "            strToSend = 'i, n, ' + str(int(time.time()*100)) + ',' + encoded_string.decode() + ',' + '\\n'\n",
    "            self.pub.send(strToSend)\n",
    "            \n",
    "# Class to subscribe to SAS Event Stream Processing to receive scored images - optionally save to video\n",
    "class video_sub():\n",
    "    def __init__(self, window, save_to_file=True, filename='', video_fps=25, video_size=(1920,1080)):\n",
    "        self.ws = websocket.WebSocketApp(window.subscriber_url+\"?format=json&mode=streaming&pagesize=1&schema=false\",\n",
    "                                 on_message = self.on_message,\n",
    "                                 on_error = self.on_error,\n",
    "                                 on_close = self.on_close)\n",
    "        self.ws.on_open = self.on_open\n",
    "        self.save_to_file = save_to_file\n",
    "        if save_to_file == True:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"H264\")\n",
    "            self.out = cv2.VideoWriter(filename, fourcc, video_fps, video_size)\n",
    "        threading.Thread(target=self.ws.run_forever, daemon=True).start()\n",
    "        print('Subscriber Started!')\n",
    "        return\n",
    "\n",
    "    def on_message(self, message):\n",
    "        try:\n",
    "            data = json.loads(message)\n",
    "            frame = self.highlightImage(data)\n",
    "            if self.save_to_file == True:\n",
    "                self.out.write(frame)\n",
    "            cv2.imshow('frame',frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    def on_error(self, error):\n",
    "        print(error)\n",
    "\n",
    "    def on_close(self):\n",
    "        print(\"Websocket closed!\")\n",
    "\n",
    "    def on_open(self):\n",
    "        print('Websocket open!')\n",
    "        \n",
    "    def highlightImage(self, data):\n",
    "        object_list = ['mask', 'no_mask']\n",
    "        color_palette = [\n",
    "            (0,255,64), #green\n",
    "            (0,64,255), #red\n",
    "        ]\n",
    "        #BGR Colorcodes\n",
    "        obj_colors = {}\n",
    "        i = 0\n",
    "        for _object in object_list:\n",
    "            obj_colors[_object] = color_palette[i]\n",
    "            i += 1\n",
    "\n",
    "        row = data['events'][0]['event']\n",
    "        numberOfObjects = data['events'][0]['event']['_nObjects_']\n",
    "        imageBufferBase64 = data['events'][0]['event']['image']['image']\n",
    "\n",
    "        nparr = np.frombuffer(base64.b64decode(imageBufferBase64), dtype=np.uint8)\n",
    "        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "        image_h, image_w,_ = frame.shape\n",
    "        for i in range(0, int(float(numberOfObjects))):\n",
    "            obj = row['_Object' + str(i) + '_'].strip()\n",
    "            prob = float(row['_P_Object' + str(i) + '_'])\n",
    "            if prob > 0.8:\n",
    "                probability = \" (\" + str(round(prob * 100, 2)) + \"%)\"\n",
    "                x = float(row['_Object' + str(i) + '_x'])\n",
    "                y = float(row['_Object' + str(i) + '_y'])\n",
    "                width = float(row['_Object' + str(i) + '_width'])\n",
    "                height = float(row['_Object' + str(i) + '_height'])\n",
    "                x1 = int(image_w * (x - width / 2))\n",
    "                y1 = int(image_h * (y - height/ 2))\n",
    "                x2 = int(image_w * (x + width / 2))\n",
    "                y2 = int(image_h * (y + height/ 2))\n",
    "                if obj in obj_colors:\n",
    "                    bbox_color = obj_colors[obj]\n",
    "                    border_offset = 3\n",
    "                    cv2.rectangle(frame,(x1,y1),(x2,y2),bbox_color,1)\n",
    "                    (label_width, label_height), baseline = cv2.getTextSize(obj + probability, cv2.FONT_HERSHEY_DUPLEX, 0.4, 1)\n",
    "                    cv2.rectangle(frame,(x1,y1),(x1+label_width+10,y1-label_height-border_offset-10),bbox_color,-1)\n",
    "                    cv2.putText(frame, obj + probability, (x1+5, y1-border_offset-5), cv2.FONT_HERSHEY_DUPLEX, 0.4, (0, 0, 0), 1,\n",
    "                        cv2.LINE_AA)\n",
    "        return frame\n",
    "\n",
    "publisher = video_pub(publisher=pub,\n",
    "                      video_file='/data/notebooks/Face_Mask_Detection/video.avi',\n",
    "                      #video_file=0,\n",
    "                      video_quality=95)\n",
    "subscriber = video_sub(window=model_score, \n",
    "                       save_to_file=True, \n",
    "                       filename='/data/notebooks/Face_Mask_Detection/scored_video2.avi', \n",
    "                       video_fps=30, \n",
    "                       video_size=(1920,1080))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
